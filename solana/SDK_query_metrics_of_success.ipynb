{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data using the ShroomDK API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = st.secrets[\"flipside\"][\"api_key\"]\n",
    "TTL_MINUTES = 15\n",
    "\n",
    "PAGE_SIZE = 100000\n",
    "PAGE_NUMBER = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = [\"TRUE\", \"FALSE\"]\n",
    "order_vars = [\"total_fee\", \"total_tx\"]\n",
    "join_types = [\"left\", \"inner\"]\n",
    "date_pairs = [\n",
    "    (\"2022-01-01\", \"2022-02-01\"),\n",
    "    (\"2022-02-01\", \"2022-03-01\"),\n",
    "    (\"2022-03-01\", \"2022-04-01\"),\n",
    "    (\"2022-04-01\", \"2022-05-01\"),\n",
    "    (\"2022-05-01\", \"2022-06-01\"),\n",
    "    (\"2022-06-01\", \"2022-07-01\"),\n",
    "    (\"2022-07-01\", f\"{datetime.date.today():%Y-%m-%d}\"),\n",
    "]\n",
    "dates = [\n",
    "    f\"{x:%Y-%m-%d}\"\n",
    "    for x in pd.date_range(datetime.date(2022, 1, 1), datetime.datetime.today())\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query(query, ttl_min, api_key):\n",
    "    r = requests.post(\n",
    "        \"https://node-api.flipsidecrypto.com/queries\",\n",
    "        data=json.dumps({\"sql\": query, \"ttlMinutes\": ttl_min}),\n",
    "        headers={\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"x-api-key\": api_key,\n",
    "        },\n",
    "    )\n",
    "    if r.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Error creating query, got response: \"\n",
    "            + r.text\n",
    "            + \"with status code: \"\n",
    "            + str(r.status_code)\n",
    "        )\n",
    "\n",
    "    return json.loads(r.text)\n",
    "\n",
    "def submit_queries(\n",
    "    template,\n",
    "    sleep_time=2,\n",
    "    **kwargs,\n",
    "):\n",
    "    query_dict = {}\n",
    "    redos = {}\n",
    "\n",
    "    template_name = template.split(\"@\")[1][6:]\n",
    "    print(f\"Working on {template_name}...\")\n",
    "    combos = [dict(zip(kwargs.keys(), x)) for x in itertools.product(*kwargs.values())]\n",
    "\n",
    "    for i, x in enumerate(combos.copy()):\n",
    "        for k, v in x.copy().items():\n",
    "            if type(v) == tuple:\n",
    "                pairs = combos[i].pop(k)\n",
    "                for j, y in enumerate(pairs):\n",
    "                    combos[i][f\"{k}_{j}\"] = y\n",
    "    print(f\"Submitting {len(combos)} queries...\")\n",
    "    queries = {}\n",
    "    for i, x in enumerate(combos):\n",
    "        # for k,v in x:\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Submitting job {i}/{len(combos)}\")\n",
    "        name = f\"{template_name}__{'--'.join(x.values())}\"\n",
    "        qry = template.format(**x)\n",
    "        queries[name] = {\"query\": qry}\n",
    "        try:\n",
    "            q = create_query(qry, TTL_MINUTES, API_KEY)\n",
    "            token = q.get(\"token\")\n",
    "            time.sleep(sleep_time)\n",
    "            query_dict[name] = {\"query\": qry, \"token\": token}\n",
    "        except Exception:  # reattempt run\n",
    "            try:\n",
    "                time.sleep(5)\n",
    "                q = create_query(qry, TTL_MINUTES, API_KEY)\n",
    "                token = q.get(\"token\")\n",
    "                time.sleep(sleep_time)\n",
    "                query_dict[name] = {\"query\": qry, \"token\": token}\n",
    "            except Exception as e:\n",
    "                print(f\"This query is not submitted: {name}\")\n",
    "                redos[name] = {\"exception\": e, \"query\": qry}\n",
    "                time.sleep(sleep_time)\n",
    "    return query_dict, redos\n",
    "\n",
    "\n",
    "\n",
    "def check_query(token, api_key):\n",
    "    r = requests.get(\n",
    "       f'https://node-api.flipsidecrypto.com/queries/{token}?pageNumber={PAGE_NUMBER}&pageSize={PAGE_SIZE}',\n",
    "        headers={\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"x-api-key\": api_key,\n",
    "        },\n",
    "    )\n",
    "    if r.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Error getting query results, got response: \"\n",
    "            + r.text\n",
    "            + \"with status code: \"\n",
    "            + str(r.status_code)\n",
    "        )\n",
    "\n",
    "    data = json.loads(r.text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tps_info_template = \"\"\"\n",
    "--sql @name: all_tps_info@\n",
    "-- TODO: use Kida's regex?\n",
    "with consumption_tx as (\n",
    "    select\n",
    "        t.block_timestamp,\n",
    "        t.tx_id,\n",
    "        t.fee,\n",
    "        t.succeeded,\n",
    "        sum(\n",
    "            split(\n",
    "                regexp_substr(s.value, '[0-9]* of [0-9]*'),\n",
    "                ' of '\n",
    "            ) [0] :: int\n",
    "        ) as compute_units_used,\n",
    "        avg(\n",
    "            split(\n",
    "                regexp_substr(s.value, '[0-9]* of [0-9]*'),\n",
    "                ' of '\n",
    "            ) [1] :: int\n",
    "        ) as avg_compute_units_requested,\n",
    "        avg(\n",
    "            split(\n",
    "                regexp_substr(s.value, '[0-9]* of [0-9]*'),\n",
    "                ' of '\n",
    "            ) [0] :: int / split(\n",
    "                regexp_substr(s.value, '[0-9]* of [0-9]*'),\n",
    "                ' of '\n",
    "            ) [1] :: int\n",
    "        ) as avg_compute_units_proportion\n",
    "    from\n",
    "        solana.core.fact_transactions t,\n",
    "        lateral flatten(input => t.log_messages) s\n",
    "    where\n",
    "        block_timestamp :: date = '{date}'\n",
    "        and s.value like '% consumed %'\n",
    "    group by\n",
    "        t.block_timestamp,\n",
    "        t.tx_id,\n",
    "        t.fee,\n",
    "        t.succeeded\n",
    ")\n",
    "select\n",
    "    date_trunc('hour', block_timestamp) as datetime,\n",
    "    -- total tx\n",
    "    count(tx_id) as total_tx,\n",
    "    sum(fee) as total_fee,\n",
    "    avg(fee) as avg_total_fee,\n",
    "    sum(compute_units_used) as total_compute_units_used,\n",
    "    avg(compute_units_used) as total_avg_compute_units_used,\n",
    "    avg(avg_compute_units_requested) as total_avg_compute_units_requested,\n",
    "    avg(avg_compute_units_proportion) as total_avg_compute_units_proportion,\n",
    "    -- successful tx:\n",
    "    count(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then succeeded\n",
    "            else NULL\n",
    "        end\n",
    "    ) as successful_tx,\n",
    "    sum(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then fee\n",
    "            else NULL\n",
    "        end\n",
    "    ) as successful_fee,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then fee\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_successful_fee,\n",
    "    sum(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then compute_units_used\n",
    "            else NULL\n",
    "        end\n",
    "    ) as successful_compute_units_used,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then compute_units_used\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_successful_compute_units_used,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then avg_compute_units_requested\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_successful_compute_units_requested,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then avg_compute_units_proportion\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_successful_compute_units_proportion,\n",
    "    -- failed tx:\n",
    "    count(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then succeeded\n",
    "            else NULL\n",
    "        end\n",
    "    ) as failed_tx,\n",
    "    sum(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then fee\n",
    "            else NULL\n",
    "        end\n",
    "    ) as failed_fee,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then fee\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_failed_fee,\n",
    "    sum(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then compute_units_used\n",
    "            else NULL\n",
    "        end\n",
    "    ) as failed_compute_units_used,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then compute_units_used\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_failed_compute_units_used,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then avg_compute_units_requested\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_failed_compute_units_requested,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then avg_compute_units_proportion\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_failed_compute_units_proportion,\n",
    "    -- rates:\n",
    "    successful_tx / total_tx as success_rate,\n",
    "    total_tx / 3600 as total_tps,\n",
    "    successful_tx / 3600 as succesful_tps,\n",
    "    failed_tx / 3600 as failed_tps\n",
    "from\n",
    "    consumption_tx\n",
    "group by\n",
    "    datetime\n",
    "order by\n",
    "    datetime \n",
    "--end-sql\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on all_tps_info...\n",
      "Submitting 201 queries...\n",
      "Submitting job 0/201\n",
      "Submitting job 10/201\n",
      "Submitting job 20/201\n",
      "Submitting job 30/201\n",
      "Submitting job 40/201\n",
      "Submitting job 50/201\n",
      "Submitting job 60/201\n",
      "Submitting job 70/201\n",
      "Submitting job 80/201\n",
      "Submitting job 90/201\n",
      "Submitting job 100/201\n",
      "Submitting job 110/201\n",
      "Submitting job 120/201\n",
      "Submitting job 130/201\n",
      "Submitting job 140/201\n",
      "Submitting job 150/201\n",
      "Submitting job 160/201\n",
      "Submitting job 170/201\n",
      "Submitting job 180/201\n",
      "Submitting job 190/201\n",
      "Submitting job 200/201\n"
     ]
    }
   ],
   "source": [
    "queries, redos = submit_queries(\n",
    "    all_tps_info_template,\n",
    "    0,\n",
    "    date=dates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 201)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries), len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/queries.json', 'w') as f:\n",
    "    json.dump(queries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_tps_info__2022-01-08: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-02-08: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-02-10: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-02-20: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-03-02: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-03-07: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-03-29: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-05-04: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-05-09: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-05-16: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-06-06: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-06-22: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-07-02: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-07-10: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-07-15: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n"
     ]
    }
   ],
   "source": [
    "# time.sleep(600) # give everything 10+ minutes to run\n",
    "data_dict = {}\n",
    "running = {}\n",
    "for k, v in queries.items():\n",
    "    try:\n",
    "        result = check_query(v[\"token\"], API_KEY)\n",
    "        if result[\"status\"] == \"running\":\n",
    "            running[k] = v\n",
    "        else:\n",
    "            data_dict[k] = result\n",
    "    except Exception as e:\n",
    "        print(f\"{k}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure exactly what is causing this division by 0 error.\n",
    "This is a SQL error which occurs on Velocity as well for these dates.\n",
    "Either `total_tx` (in `successful_tx / total_tx as success_rate`), or\n",
    "```sql\n",
    "split(\n",
    "    regexp_substr(s.value, '[0-9]* of [0-9]*'),\n",
    "    ' of '\n",
    ") [1] :: int\n",
    "```\n",
    "is 0 for one of the hours during that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 186)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(running), len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data.json', 'w') as f:\n",
    "    json.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_tps = []\n",
    "for k in data_dict:\n",
    "    if \"all\" in k:\n",
    "        query_data = data_dict[k]\n",
    "        df = pd.DataFrame(query_data[\"results\"], columns=query_data[\"columnLabels\"])\n",
    "        dfs_tps.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs_tps).sort_values(by='DATETIME').reset_index(drop=True)\n",
    "df['DATETIME'] = pd.to_datetime(df.DATETIME)\n",
    "df = df[df['DATETIME'] < pd.to_datetime(datetime.date.today())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df.columns:\n",
    "    if 'FEE' in x:\n",
    "        df[x] = df[x] / 1_000_000_000 # convert to SOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/tps.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate how to use data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/tps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATETIME', 'TOTAL_TX', 'TOTAL_FEE', 'AVG_TOTAL_FEE',\n",
       "       'TOTAL_COMPUTE_UNITS_USED', 'AVG_COMPUTE_UNITS_USED',\n",
       "       'TOTAL_AVG_COMPUTE_UNITS_REQUESTED',\n",
       "       'TOTAL_AVG_COMPUTE_UNITS_PROPORTION', 'SUCCESSFUL_TX', 'SUCCESSFUL_FEE',\n",
       "       'AVG_SUCCESSFUL_FEE', 'SUCCESSFUL_COMPUTE_UNITS_USED',\n",
       "       'AVG_SUCCESSFUL_COMPUTE_UNITS_USED',\n",
       "       'AVG_SUCCESSFUL_COMPUTE_UNITS_REQUESTED',\n",
       "       'AVG_SUCCESSFUL_COMPUTE_UNITS_PROPORTION', 'FAILED_TX', 'FAILED_FEE',\n",
       "       'AVG_FAILED_FEE', 'FAILED_COMPUTE_UNITS_USED',\n",
       "       'AVG_FAILED_COMPUTE_UNITS_USED', 'AVG_FAILED_COMPUTE_UNITS_REQUESTED',\n",
       "       'AVG_FAILED_COMPUTE_UNITS_PROPORTION', 'SUCCESS_RATE', 'TOTAL_TPS',\n",
       "       'SUCCESFUL_TPS', 'FAILED_TPS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tps_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_TPS\",\n",
    "        \"SUCCESFUL_TPS\",\n",
    "        \"FAILED_TPS\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "fee_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_FEE\",\n",
    "        \"SUCCESSFUL_FEE\",\n",
    "        \"FAILED_FEE\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "avg_fee_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"AVG_TOTAL_FEE\",\n",
    "        \"AVG_SUCCESSFUL_FEE\",\n",
    "        \"AVG_FAILED_FEE\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "tx_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_TX\",\n",
    "        \"SUCCESSFUL_TX\",\n",
    "        \"FAILED_TX\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "compute_units_used_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_COMPUTE_UNITS_USED\",\n",
    "        \"SUCCESSFUL_COMPUTE_UNITS_USED\",\n",
    "        \"FAILED_COMPUTE_UNITS_USED\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "avg_compute_units_used_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_AVG_COMPUTE_UNITS_USED\",\n",
    "        \"AVG_SUCCESSFUL_COMPUTE_UNITS_USED\",\n",
    "        \"AVG_FAILED_COMPUTE_UNITS_USED\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "avg_compute_units_requested_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_AVG_COMPUTE_UNITS_REQUESTED\",\n",
    "        \"AVG_SUCCESSFUL_COMPUTE_UNITS_REQUESTED\",\n",
    "        \"AVG_FAILED_COMPUTE_UNITS_REQUESTED\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "avg_compute_units_proportion_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_AVG_COMPUTE_UNITS_PROPORTION\",\n",
    "        \"AVG_SUCCESSFUL_COMPUTE_UNITS_PROPORTION\",\n",
    "        \"AVG_FAILED_COMPUTE_UNITS_PROPORTION\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tps_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_TPS\",\n",
    "        \"SUCCESFUL_TPS\",\n",
    "        \"FAILED_TPS\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>TOTAL_TPS</th>\n",
       "      <th>SUCCESFUL_TPS</th>\n",
       "      <th>FAILED_TPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>816.017778</td>\n",
       "      <td>624.088056</td>\n",
       "      <td>191.929722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>806.275833</td>\n",
       "      <td>614.596667</td>\n",
       "      <td>191.679167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>675.293056</td>\n",
       "      <td>463.925278</td>\n",
       "      <td>211.367778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>777.086111</td>\n",
       "      <td>567.031944</td>\n",
       "      <td>210.054167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>833.851111</td>\n",
       "      <td>626.094167</td>\n",
       "      <td>207.756944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>2022-07-19 19:00:00</td>\n",
       "      <td>557.755000</td>\n",
       "      <td>406.186111</td>\n",
       "      <td>151.568889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>2022-07-19 20:00:00</td>\n",
       "      <td>454.158889</td>\n",
       "      <td>332.322500</td>\n",
       "      <td>121.836389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>2022-07-19 21:00:00</td>\n",
       "      <td>467.001944</td>\n",
       "      <td>337.880833</td>\n",
       "      <td>129.121111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>2022-07-19 22:00:00</td>\n",
       "      <td>529.850833</td>\n",
       "      <td>413.622222</td>\n",
       "      <td>116.228611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>2022-07-19 23:00:00</td>\n",
       "      <td>529.319722</td>\n",
       "      <td>411.062778</td>\n",
       "      <td>118.256944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4436 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATETIME   TOTAL_TPS  SUCCESFUL_TPS  FAILED_TPS\n",
       "0     2022-01-01 00:00:00  816.017778     624.088056  191.929722\n",
       "1     2022-01-01 01:00:00  806.275833     614.596667  191.679167\n",
       "2     2022-01-01 02:00:00  675.293056     463.925278  211.367778\n",
       "3     2022-01-01 03:00:00  777.086111     567.031944  210.054167\n",
       "4     2022-01-01 04:00:00  833.851111     626.094167  207.756944\n",
       "...                   ...         ...            ...         ...\n",
       "4431  2022-07-19 19:00:00  557.755000     406.186111  151.568889\n",
       "4432  2022-07-19 20:00:00  454.158889     332.322500  121.836389\n",
       "4433  2022-07-19 21:00:00  467.001944     337.880833  129.121111\n",
       "4434  2022-07-19 22:00:00  529.850833     413.622222  116.228611\n",
       "4435  2022-07-19 23:00:00  529.319722     411.062778  118.256944\n",
       "\n",
       "[4436 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_319913/3233464772.py:1: FutureWarning: Dropping of nuisance columns in rolling operations is deprecated; in a future version this will raise TypeError. Select only valid columns before calling the operation. Dropped columns were Index(['DATETIME'], dtype='object')\n",
      "  tps_df.rolling(24).mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL_TPS</th>\n",
       "      <th>SUCCESFUL_TPS</th>\n",
       "      <th>FAILED_TPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>551.114803</td>\n",
       "      <td>384.947558</td>\n",
       "      <td>166.167245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>550.850405</td>\n",
       "      <td>384.393438</td>\n",
       "      <td>166.456968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>549.492616</td>\n",
       "      <td>382.738067</td>\n",
       "      <td>166.754549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>549.945289</td>\n",
       "      <td>384.749398</td>\n",
       "      <td>165.195891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>550.826296</td>\n",
       "      <td>389.027847</td>\n",
       "      <td>161.798449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4436 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TOTAL_TPS  SUCCESFUL_TPS  FAILED_TPS\n",
       "0            NaN            NaN         NaN\n",
       "1            NaN            NaN         NaN\n",
       "2            NaN            NaN         NaN\n",
       "3            NaN            NaN         NaN\n",
       "4            NaN            NaN         NaN\n",
       "...          ...            ...         ...\n",
       "4431  551.114803     384.947558  166.167245\n",
       "4432  550.850405     384.393438  166.456968\n",
       "4433  549.492616     382.738067  166.754549\n",
       "4434  549.945289     384.749398  165.195891\n",
       "4435  550.826296     389.027847  161.798449\n",
       "\n",
       "[4436 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tps_df.rolling(24).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_319913/4250769966.py:1: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  avg_fee_df.melt()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATETIME</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATETIME</td>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATETIME</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATETIME</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATETIME</td>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39919</th>\n",
       "      <td>value</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39920</th>\n",
       "      <td>value</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39921</th>\n",
       "      <td>value</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39922</th>\n",
       "      <td>value</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39923</th>\n",
       "      <td>value</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39924 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       variable                value\n",
       "0      DATETIME  2022-01-01 00:00:00\n",
       "1      DATETIME  2022-01-01 01:00:00\n",
       "2      DATETIME  2022-01-01 02:00:00\n",
       "3      DATETIME  2022-01-01 03:00:00\n",
       "4      DATETIME  2022-01-01 04:00:00\n",
       "...         ...                  ...\n",
       "39919     value             0.000006\n",
       "39920     value             0.000006\n",
       "39921     value             0.000008\n",
       "39922     value             0.000006\n",
       "39923     value             0.000007\n",
       "\n",
       "[39924 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_fee_df.melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('subgrounds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef43022a1ed6bdfb3d34bac2207c7479121de95eb80151a14c38174bba76665e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
