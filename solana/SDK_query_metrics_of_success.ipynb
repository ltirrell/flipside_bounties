{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data using the ShroomDK API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = st.secrets[\"flipside\"][\"api_key\"]\n",
    "TTL_MINUTES = 60\n",
    "\n",
    "PAGE_SIZE = 100000\n",
    "PAGE_NUMBER = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = [\"TRUE\", \"FALSE\"]\n",
    "order_vars = [\"total_fee\", \"total_tx\"]\n",
    "join_types = [\"left\", \"inner\"]\n",
    "date_pairs = [\n",
    "    (\"2022-01-01\", \"2022-02-01\"),\n",
    "    (\"2022-02-01\", \"2022-03-01\"),\n",
    "    (\"2022-03-01\", \"2022-04-01\"),\n",
    "    (\"2022-04-01\", \"2022-05-01\"),\n",
    "    (\"2022-05-01\", \"2022-06-01\"),\n",
    "    (\"2022-06-01\", \"2022-07-01\"),\n",
    "    (\"2022-07-01\", \"2022-08-01\"),\n",
    "    (\"2022-08-01\", \"2022-09-01\"),\n",
    "    (\"2022-09-01\", f\"{datetime.date.today():%Y-%m-%d}\"),\n",
    "]\n",
    "dates = [\n",
    "    f\"{x:%Y-%m-%d}\"\n",
    "    for x in pd.date_range(datetime.date(2022, 1, 1), datetime.datetime.today())\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query(query, ttl_min, api_key):\n",
    "    r = requests.post(\n",
    "        \"https://node-api.flipsidecrypto.com/queries\",\n",
    "        data=json.dumps({\"sql\": query, \"ttlMinutes\": ttl_min}),\n",
    "        headers={\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"x-api-key\": api_key,\n",
    "        },\n",
    "    )\n",
    "    if r.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Error creating query, got response: \"\n",
    "            + r.text\n",
    "            + \"with status code: \"\n",
    "            + str(r.status_code)\n",
    "        )\n",
    "\n",
    "    return json.loads(r.text)\n",
    "\n",
    "def submit_queries(\n",
    "    template,\n",
    "    sleep_time=2,\n",
    "    **kwargs,\n",
    "):\n",
    "    query_dict = {}\n",
    "    redos = {}\n",
    "\n",
    "    template_name = template.split(\"@\")[1][6:]\n",
    "    print(f\"Working on {template_name}...\")\n",
    "    combos = [dict(zip(kwargs.keys(), x)) for x in itertools.product(*kwargs.values())]\n",
    "\n",
    "    for i, x in enumerate(combos.copy()):\n",
    "        for k, v in x.copy().items():\n",
    "            if type(v) == tuple:\n",
    "                pairs = combos[i].pop(k)\n",
    "                for j, y in enumerate(pairs):\n",
    "                    combos[i][f\"{k}_{j}\"] = y\n",
    "    print(f\"Submitting {len(combos)} queries...\")\n",
    "    queries = {}\n",
    "    for i, x in enumerate(combos):\n",
    "        # for k,v in x:\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Submitting job {i}/{len(combos)}\")\n",
    "        name = f\"{template_name}__{'--'.join(x.values())}\"\n",
    "        qry = template.format(**x)\n",
    "        queries[name] = {\"query\": qry}\n",
    "        try:\n",
    "            q = create_query(qry, TTL_MINUTES, API_KEY)\n",
    "            token = q.get(\"token\")\n",
    "            time.sleep(sleep_time)\n",
    "            query_dict[name] = {\"query\": qry, \"token\": token}\n",
    "        except Exception:  # reattempt run\n",
    "            try:\n",
    "                time.sleep(5)\n",
    "                q = create_query(qry, TTL_MINUTES, API_KEY)\n",
    "                token = q.get(\"token\")\n",
    "                time.sleep(sleep_time)\n",
    "                query_dict[name] = {\"query\": qry, \"token\": token}\n",
    "            except Exception as e:\n",
    "                print(f\"This query is not submitted: {name}\")\n",
    "                redos[name] = {\"exception\": e, \"query\": qry}\n",
    "                time.sleep(sleep_time)\n",
    "    return query_dict, redos\n",
    "\n",
    "\n",
    "\n",
    "def check_query(token, api_key):\n",
    "    r = requests.get(\n",
    "       f'https://node-api.flipsidecrypto.com/queries/{token}?pageNumber={PAGE_NUMBER}&pageSize={PAGE_SIZE}',\n",
    "        headers={\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"x-api-key\": api_key,\n",
    "        },\n",
    "    )\n",
    "    if r.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Error getting query results, got response: \"\n",
    "            + r.text\n",
    "            + \"with status code: \"\n",
    "            + str(r.status_code)\n",
    "        )\n",
    "\n",
    "    data = json.loads(r.text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tps_info_template = \"\"\"\n",
    "--sql @name: all_tps_info@\n",
    "-- TODO: use Kida's regex?\n",
    "with consumption_tx as (\n",
    "    select\n",
    "        t.block_timestamp,\n",
    "        t.tx_id,\n",
    "        t.fee,\n",
    "        t.succeeded,\n",
    "        sum(\n",
    "            split(\n",
    "                regexp_substr(s.value, '[0-9]* of [0-9]*'),\n",
    "                ' of '\n",
    "            ) [0] :: int\n",
    "        ) as compute_units_used,\n",
    "        avg(\n",
    "            split(\n",
    "                regexp_substr(s.value, '[0-9]* of [0-9]*'),\n",
    "                ' of '\n",
    "            ) [1] :: int\n",
    "        ) as avg_compute_units_requested,\n",
    "        avg(\n",
    "            split(\n",
    "                regexp_substr(s.value, '[0-9]* of [0-9]*'),\n",
    "                ' of '\n",
    "            ) [0] :: int / split(\n",
    "                regexp_substr(s.value, '[0-9]* of [0-9]*'),\n",
    "                ' of '\n",
    "            ) [1] :: int\n",
    "        ) as avg_compute_units_proportion\n",
    "    from\n",
    "        solana.core.fact_transactions t,\n",
    "        lateral flatten(input => t.log_messages) s\n",
    "    where\n",
    "        block_timestamp :: date = '{date}'\n",
    "        and s.value like '% consumed %'\n",
    "    group by\n",
    "        t.block_timestamp,\n",
    "        t.tx_id,\n",
    "        t.fee,\n",
    "        t.succeeded\n",
    ")\n",
    "select\n",
    "    date_trunc('hour', block_timestamp) as datetime,\n",
    "    -- total tx\n",
    "    count(tx_id) as total_tx,\n",
    "    sum(fee) as total_fee,\n",
    "    avg(fee) as avg_total_fee,\n",
    "    sum(compute_units_used) as total_compute_units_used,\n",
    "    avg(compute_units_used) as total_avg_compute_units_used,\n",
    "    avg(avg_compute_units_requested) as total_avg_compute_units_requested,\n",
    "    avg(avg_compute_units_proportion) as total_avg_compute_units_proportion,\n",
    "    -- successful tx:\n",
    "    count(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then succeeded\n",
    "            else NULL\n",
    "        end\n",
    "    ) as successful_tx,\n",
    "    sum(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then fee\n",
    "            else NULL\n",
    "        end\n",
    "    ) as successful_fee,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then fee\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_successful_fee,\n",
    "    sum(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then compute_units_used\n",
    "            else NULL\n",
    "        end\n",
    "    ) as successful_compute_units_used,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then compute_units_used\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_successful_compute_units_used,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then avg_compute_units_requested\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_successful_compute_units_requested,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'TRUE' then avg_compute_units_proportion\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_successful_compute_units_proportion,\n",
    "    -- failed tx:\n",
    "    count(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then succeeded\n",
    "            else NULL\n",
    "        end\n",
    "    ) as failed_tx,\n",
    "    sum(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then fee\n",
    "            else NULL\n",
    "        end\n",
    "    ) as failed_fee,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then fee\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_failed_fee,\n",
    "    sum(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then compute_units_used\n",
    "            else NULL\n",
    "        end\n",
    "    ) as failed_compute_units_used,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then compute_units_used\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_failed_compute_units_used,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then avg_compute_units_requested\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_failed_compute_units_requested,\n",
    "    avg(\n",
    "        case\n",
    "            when succeeded = 'FALSE' then avg_compute_units_proportion\n",
    "            else NULL\n",
    "        end\n",
    "    ) as avg_failed_compute_units_proportion,\n",
    "    -- rates:\n",
    "    successful_tx / total_tx as success_rate,\n",
    "    total_tx / 3600 as total_tps,\n",
    "    successful_tx / 3600 as succesful_tps,\n",
    "    failed_tx / 3600 as failed_tps\n",
    "from\n",
    "    consumption_tx\n",
    "group by\n",
    "    datetime\n",
    "order by\n",
    "    datetime \n",
    "--end-sql\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on all_tps_info...\n",
      "Submitting 272 queries...\n",
      "Submitting job 0/272\n",
      "Submitting job 10/272\n",
      "Submitting job 20/272\n",
      "Submitting job 30/272\n",
      "Submitting job 40/272\n",
      "Submitting job 50/272\n",
      "Submitting job 60/272\n",
      "Submitting job 70/272\n",
      "Submitting job 80/272\n",
      "Submitting job 90/272\n",
      "Submitting job 100/272\n",
      "Submitting job 110/272\n",
      "Submitting job 120/272\n",
      "Submitting job 130/272\n",
      "Submitting job 140/272\n",
      "Submitting job 150/272\n",
      "Submitting job 160/272\n",
      "Submitting job 170/272\n",
      "Submitting job 180/272\n",
      "Submitting job 190/272\n",
      "Submitting job 200/272\n",
      "Submitting job 210/272\n",
      "Submitting job 220/272\n",
      "Submitting job 230/272\n",
      "Submitting job 240/272\n",
      "Submitting job 250/272\n",
      "Submitting job 260/272\n",
      "Submitting job 270/272\n"
     ]
    }
   ],
   "source": [
    "queries, redos = submit_queries(\n",
    "    all_tps_info_template,\n",
    "    0,\n",
    "    date=dates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 272)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries), len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/queries.json', 'w') as f:\n",
    "    json.dump(queries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_tps_info__2022-01-08: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-02-08: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-02-10: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-02-20: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-03-02: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-03-07: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-03-29: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-05-04: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-05-09: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-05-16: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-06-06: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-06-22: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-07-02: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-07-10: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-07-15: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-07-26: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-07-28: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-01: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-03: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-05: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-06: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-10: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-11: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-13: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-15: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-17: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-19: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-20: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-25: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-08-26: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-09-07: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-09-09: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-09-11: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-09-13: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-09-18: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-09-23: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-09-24: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n",
      "all_tps_info__2022-09-27: Error getting query results, got response: {\"errors\":\"Division by zero\"}with status code: 400\n"
     ]
    }
   ],
   "source": [
    "time.sleep(600) # give everything 10+ minutes to run\n",
    "data_dict = {}\n",
    "running = {}\n",
    "for k, v in queries.items():\n",
    "    try:\n",
    "        result = check_query(v[\"token\"], API_KEY)\n",
    "        if result[\"status\"] == \"running\":\n",
    "            running[k] = v\n",
    "        else:\n",
    "            data_dict[k] = result\n",
    "    except Exception as e:\n",
    "        print(f\"{k}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure exactly what is causing this division by 0 error.\n",
    "This is a SQL error which occurs on Velocity as well for these dates.\n",
    "Either `total_tx` (in `successful_tx / total_tx as success_rate`), or\n",
    "```sql\n",
    "split(\n",
    "    regexp_substr(s.value, '[0-9]* of [0-9]*'),\n",
    "    ' of '\n",
    ") [1] :: int\n",
    "```\n",
    "is 0 for one of the hours during that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 234)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(running), len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data.json', 'w') as f:\n",
    "    json.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13970588235294118"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(data_dict) - len(dates)) / len(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_tps = []\n",
    "for k in data_dict:\n",
    "    if \"all\" in k:\n",
    "        query_data = data_dict[k]\n",
    "        df = pd.DataFrame(query_data[\"results\"], columns=query_data[\"columnLabels\"])\n",
    "        dfs_tps.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs_tps).sort_values(by='DATETIME').reset_index(drop=True)\n",
    "df['DATETIME'] = pd.to_datetime(df.DATETIME)\n",
    "df = df[df['DATETIME'] < pd.to_datetime(datetime.date.today())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df.columns:\n",
    "    if 'FEE' in x:\n",
    "        df[x] = df[x] / 1_000_000_000 # convert to SOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/tps.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate how to use data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/tps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATETIME', 'TOTAL_TX', 'TOTAL_FEE', 'AVG_TOTAL_FEE',\n",
       "       'TOTAL_COMPUTE_UNITS_USED', 'TOTAL_AVG_COMPUTE_UNITS_USED',\n",
       "       'TOTAL_AVG_COMPUTE_UNITS_REQUESTED',\n",
       "       'TOTAL_AVG_COMPUTE_UNITS_PROPORTION', 'SUCCESSFUL_TX', 'SUCCESSFUL_FEE',\n",
       "       'AVG_SUCCESSFUL_FEE', 'SUCCESSFUL_COMPUTE_UNITS_USED',\n",
       "       'AVG_SUCCESSFUL_COMPUTE_UNITS_USED',\n",
       "       'AVG_SUCCESSFUL_COMPUTE_UNITS_REQUESTED',\n",
       "       'AVG_SUCCESSFUL_COMPUTE_UNITS_PROPORTION', 'FAILED_TX', 'FAILED_FEE',\n",
       "       'AVG_FAILED_FEE', 'FAILED_COMPUTE_UNITS_USED',\n",
       "       'AVG_FAILED_COMPUTE_UNITS_USED', 'AVG_FAILED_COMPUTE_UNITS_REQUESTED',\n",
       "       'AVG_FAILED_COMPUTE_UNITS_PROPORTION', 'SUCCESS_RATE', 'TOTAL_TPS',\n",
       "       'SUCCESFUL_TPS', 'FAILED_TPS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tps_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_TPS\",\n",
    "        \"SUCCESFUL_TPS\",\n",
    "        \"FAILED_TPS\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "fee_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_FEE\",\n",
    "        \"SUCCESSFUL_FEE\",\n",
    "        \"FAILED_FEE\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "avg_fee_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"AVG_TOTAL_FEE\",\n",
    "        \"AVG_SUCCESSFUL_FEE\",\n",
    "        \"AVG_FAILED_FEE\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "tx_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_TX\",\n",
    "        \"SUCCESSFUL_TX\",\n",
    "        \"FAILED_TX\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "compute_units_used_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_COMPUTE_UNITS_USED\",\n",
    "        \"SUCCESSFUL_COMPUTE_UNITS_USED\",\n",
    "        \"FAILED_COMPUTE_UNITS_USED\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "avg_compute_units_used_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_AVG_COMPUTE_UNITS_USED\",\n",
    "        \"AVG_SUCCESSFUL_COMPUTE_UNITS_USED\",\n",
    "        \"AVG_FAILED_COMPUTE_UNITS_USED\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "avg_compute_units_requested_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_AVG_COMPUTE_UNITS_REQUESTED\",\n",
    "        \"AVG_SUCCESSFUL_COMPUTE_UNITS_REQUESTED\",\n",
    "        \"AVG_FAILED_COMPUTE_UNITS_REQUESTED\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n",
    "avg_compute_units_proportion_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_AVG_COMPUTE_UNITS_PROPORTION\",\n",
    "        \"AVG_SUCCESSFUL_COMPUTE_UNITS_PROPORTION\",\n",
    "        \"AVG_FAILED_COMPUTE_UNITS_PROPORTION\",\n",
    "    ]\n",
    "].melt(id_vars=\"DATETIME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tps_df = df[\n",
    "    [\n",
    "        \"DATETIME\",\n",
    "        \"TOTAL_TPS\",\n",
    "        \"SUCCESFUL_TPS\",\n",
    "        \"FAILED_TPS\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>TOTAL_TPS</th>\n",
       "      <th>SUCCESFUL_TPS</th>\n",
       "      <th>FAILED_TPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>816.017778</td>\n",
       "      <td>624.088056</td>\n",
       "      <td>191.929722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>806.275833</td>\n",
       "      <td>614.596667</td>\n",
       "      <td>191.679167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>675.293056</td>\n",
       "      <td>463.925278</td>\n",
       "      <td>211.367778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>777.086111</td>\n",
       "      <td>567.031944</td>\n",
       "      <td>210.054167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>833.851111</td>\n",
       "      <td>626.094167</td>\n",
       "      <td>207.756944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>2022-09-28 19:00:00</td>\n",
       "      <td>445.218889</td>\n",
       "      <td>352.172222</td>\n",
       "      <td>93.046667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5584</th>\n",
       "      <td>2022-09-28 20:00:00</td>\n",
       "      <td>439.984444</td>\n",
       "      <td>351.374167</td>\n",
       "      <td>88.610278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585</th>\n",
       "      <td>2022-09-28 21:00:00</td>\n",
       "      <td>389.107500</td>\n",
       "      <td>311.995556</td>\n",
       "      <td>77.111944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>2022-09-28 22:00:00</td>\n",
       "      <td>390.909444</td>\n",
       "      <td>311.299722</td>\n",
       "      <td>79.609722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>2022-09-28 23:00:00</td>\n",
       "      <td>423.183889</td>\n",
       "      <td>344.194444</td>\n",
       "      <td>78.989444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5588 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATETIME   TOTAL_TPS  SUCCESFUL_TPS  FAILED_TPS\n",
       "0     2022-01-01 00:00:00  816.017778     624.088056  191.929722\n",
       "1     2022-01-01 01:00:00  806.275833     614.596667  191.679167\n",
       "2     2022-01-01 02:00:00  675.293056     463.925278  211.367778\n",
       "3     2022-01-01 03:00:00  777.086111     567.031944  210.054167\n",
       "4     2022-01-01 04:00:00  833.851111     626.094167  207.756944\n",
       "...                   ...         ...            ...         ...\n",
       "5583  2022-09-28 19:00:00  445.218889     352.172222   93.046667\n",
       "5584  2022-09-28 20:00:00  439.984444     351.374167   88.610278\n",
       "5585  2022-09-28 21:00:00  389.107500     311.995556   77.111944\n",
       "5586  2022-09-28 22:00:00  390.909444     311.299722   79.609722\n",
       "5587  2022-09-28 23:00:00  423.183889     344.194444   78.989444\n",
       "\n",
       "[5588 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_425556/3233464772.py:1: FutureWarning: Dropping of nuisance columns in rolling operations is deprecated; in a future version this will raise TypeError. Select only valid columns before calling the operation. Dropped columns were Index(['DATETIME'], dtype='object')\n",
      "  tps_df.rolling(24).mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL_TPS</th>\n",
       "      <th>SUCCESFUL_TPS</th>\n",
       "      <th>FAILED_TPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>425.890162</td>\n",
       "      <td>335.852083</td>\n",
       "      <td>90.038079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5584</th>\n",
       "      <td>424.571539</td>\n",
       "      <td>335.011447</td>\n",
       "      <td>89.560093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585</th>\n",
       "      <td>422.779306</td>\n",
       "      <td>333.119699</td>\n",
       "      <td>89.659606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>421.405613</td>\n",
       "      <td>332.071007</td>\n",
       "      <td>89.334606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>422.378241</td>\n",
       "      <td>333.244363</td>\n",
       "      <td>89.133877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5588 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TOTAL_TPS  SUCCESFUL_TPS  FAILED_TPS\n",
       "0            NaN            NaN         NaN\n",
       "1            NaN            NaN         NaN\n",
       "2            NaN            NaN         NaN\n",
       "3            NaN            NaN         NaN\n",
       "4            NaN            NaN         NaN\n",
       "...          ...            ...         ...\n",
       "5583  425.890162     335.852083   90.038079\n",
       "5584  424.571539     335.011447   89.560093\n",
       "5585  422.779306     333.119699   89.659606\n",
       "5586  421.405613     332.071007   89.334606\n",
       "5587  422.378241     333.244363   89.133877\n",
       "\n",
       "[5588 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tps_df.rolling(24).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_425556/4250769966.py:1: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  avg_fee_df.melt()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATETIME</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATETIME</td>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATETIME</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATETIME</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATETIME</td>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50287</th>\n",
       "      <td>value</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50288</th>\n",
       "      <td>value</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50289</th>\n",
       "      <td>value</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50290</th>\n",
       "      <td>value</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50291</th>\n",
       "      <td>value</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       variable                value\n",
       "0      DATETIME  2022-01-01 00:00:00\n",
       "1      DATETIME  2022-01-01 01:00:00\n",
       "2      DATETIME  2022-01-01 02:00:00\n",
       "3      DATETIME  2022-01-01 03:00:00\n",
       "4      DATETIME  2022-01-01 04:00:00\n",
       "...         ...                  ...\n",
       "50287     value              0.00001\n",
       "50288     value             0.000008\n",
       "50289     value             0.000008\n",
       "50290     value             0.000008\n",
       "50291     value             0.000007\n",
       "\n",
       "[50292 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_fee_df.melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('subgrounds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef43022a1ed6bdfb3d34bac2207c7479121de95eb80151a14c38174bba76665e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
